{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c19fee",
   "metadata": {},
   "source": [
    "## Install/Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c24d98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "from contextlib import closing\n",
    "import psutil\n",
    "import tracemalloc\n",
    "import threading\n",
    "import json\n",
    "\n",
    "from essentia.standard import (\n",
    "    MonoLoader,\n",
    "    Danceability,\n",
    "    Spectrum,\n",
    "    FrameCutter,\n",
    "    Loudness,\n",
    "    RhythmExtractor2013,\n",
    "    KeyExtractor,\n",
    "    Energy,\n",
    "    TonalExtractor,\n",
    "    Inharmonicity,\n",
    "    MFCC,\n",
    "    OnsetRate,\n",
    "    SpectralCentroidTime,\n",
    "    DynamicComplexity,\n",
    "    SpectralPeaks,\n",
    "    NoveltyCurve,\n",
    "    Spectrum,\n",
    "    FrameGenerator,\n",
    "    Windowing,\n",
    "    MelBands,\n",
    "    BeatsLoudness,\n",
    "    Beatogram,\n",
    "    Meter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670504c7",
   "metadata": {},
   "source": [
    "#### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "573f64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DOWNLOAD_FOLDER = os.getenv('DOWNLOAD_FOLDER')\n",
    "CPU_THREADS = int(os.getenv('CPU_THREADS'))\n",
    "MODELS_PATH = './models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3cf45",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9c5935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes for moodtheme predictor model\n",
    "with open('data/mtg_jamendo_moodtheme-discogs-effnet-1.json', 'r') as jamendo_file:\n",
    "    jamendo_metadata = json.load(jamendo_file)\n",
    "jamendo_classes = jamendo_metadata['classes']\n",
    "\n",
    "# Get classes for instrument predictor model\n",
    "with open('data/mtg_jamendo_instrument-discogs-effnet-1.json', 'r') as jamendo_file:\n",
    "    jamendo_instrument_metadata = json.load(jamendo_file)\n",
    "jamendo_instrument_classes = jamendo_instrument_metadata['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f1082ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data = pd.read_csv('data/songs_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2cb44",
   "metadata": {},
   "source": [
    "#### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5672dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_memory_usage(process):\n",
    "    memory_summary = {f'Process {process.pid}': process.memory_info().rss / (1024 * 1024)}\n",
    "    for child in process.children(recursive=True):\n",
    "        memory_summary = memory_summary | {f'Child Process {child.pid}': child.memory_info().rss / (1024 * 1024)}\n",
    "    return memory_summary\n",
    "\n",
    "def print_memory_usage(process):\n",
    "    print(get_total_memory_usage(process))\n",
    "    snapshot = tracemalloc.take_snapshot()\n",
    "    print(f\"Top Consumer of Process {process.pid}: {snapshot.statistics('lineno')[0]}\")\n",
    "\n",
    "def monitor_memory_usage(process, kill_thread, interval=120):\n",
    "    while True:\n",
    "        try:\n",
    "            if kill_thread.value:\n",
    "                print(\"MONITOR THREAD KILLED\")\n",
    "                return\n",
    "            print_memory_usage(process)\n",
    "        except Exception as e:\n",
    "            print(f\"Thread ERROR: {e}\")\n",
    "            return\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f582f3b",
   "metadata": {},
   "source": [
    "#### Extract Features Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e61fb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_essentia_models(audio16k, audio44k):\n",
    "    features = {}\n",
    "    \n",
    "    # Get embeddings\n",
    "    discogs_embeddings = TensorflowPredictEffnetDiscogs(graphFilename=MODELS_PATH+'/discogs-effnet-bs64-1.pb', output=\"PartitionedCall:1\")(audio16k)\n",
    "    vggish_embeddings = TensorflowPredictVGGish(graphFilename=MODELS_PATH+'/audioset-vggish-3.pb', output=\"model/vggish/embeddings\")(audio16k)\n",
    "\n",
    "    # Approachability\n",
    "    approachability_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/approachability_regression-discogs-effnet-1.pb', output=\"model/Identity\")(discogs_embeddings)\n",
    "    approachability = np.median(np.squeeze(approachability_predictions))\n",
    "    \n",
    "    # Engagement\n",
    "    engagement_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/engagement_regression-discogs-effnet-1.pb', output=\"model/Identity\")(discogs_embeddings)\n",
    "    engagement = np.median(np.squeeze(engagement_predictions))\n",
    "    \n",
    "    # Arousal/Valence\n",
    "    arousal_valence_predictions = np.median(TensorflowPredict2D(graphFilename=MODELS_PATH+'/deam-audioset-vggish-2.pb', output=\"model/Identity\")(vggish_embeddings), axis=0)\n",
    "    valence = arousal_valence_predictions[0]\n",
    "    arousal = arousal_valence_predictions[1]\n",
    "    \n",
    "    # Aggressive\n",
    "    aggressive_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_aggressive-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    aggressive = np.median(aggressive_predictions, axis=0)[0]\n",
    "    \n",
    "    # Happy\n",
    "    happy_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_happy-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    happy = np.median(happy_predictions, axis=0)[0]\n",
    "    \n",
    "    # Party\n",
    "    party_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_party-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    party = np.median(party_predictions, axis=0)[0]\n",
    "    \n",
    "    # Relaxed\n",
    "    relaxed_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_relaxed-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    relaxed = np.median(relaxed_predictions, axis=0)[0]\n",
    "    \n",
    "    # Sad\n",
    "    sad_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_sad-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    sad = np.median(sad_predictions, axis=0)[0]\n",
    "    \n",
    "    # Jamendo labels\n",
    "    jamendo_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mtg_jamendo_moodtheme-discogs-effnet-1.pb')(discogs_embeddings)\n",
    "    jamendo_values = np.median(jamendo_predictions, axis=0)\n",
    "    jamendo_dict = {jamendo_class:jamendo_value for (jamendo_class, jamendo_value) in zip(jamendo_classes, jamendo_values)}\n",
    "    \n",
    "    # Jamendo instrument labels\n",
    "    jamendo_instrument_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mtg_jamendo_instrument-discogs-effnet-1.pb')(discogs_embeddings)\n",
    "    jamendo_instrument_values = np.median(jamendo_instrument_predictions, axis=0)\n",
    "    jamendo_instrument_dict = {jamendo_class:jamendo_value for (jamendo_class, jamendo_value) in zip(jamendo_instrument_classes, jamendo_instrument_values)}\n",
    "    \n",
    "    # Acoustic\n",
    "    acoustic_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_acoustic-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    acoustic = np.median(acoustic_predictions, axis=0)[0]\n",
    "    \n",
    "    # Electronic\n",
    "    electronic_predictions = TensorflowPredict2D(graphFilename=MODELS_PATH+'/mood_electronic-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings)\n",
    "    electronic = np.median(electronic_predictions, axis=0)[0]\n",
    "    \n",
    "    # Voice/Instrumental\n",
    "    voice_instrumental_predictions = np.median(TensorflowPredict2D(graphFilename=MODELS_PATH+'/voice_instrumental-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings), axis=0)\n",
    "    voice = voice_instrumental_predictions[0]\n",
    "    instrumental = voice_instrumental_predictions[1]\n",
    "    \n",
    "    # Gender (Male/Female)\n",
    "    gender_predictions = np.median(TensorflowPredict2D(graphFilename=MODELS_PATH+'/gender-audioset-vggish-1.pb', output=\"model/Softmax\")(vggish_embeddings), axis=0)\n",
    "    female = gender_predictions[0]\n",
    "    male = gender_predictions[1]\n",
    "    \n",
    "    # Timbre (Bright/Dark)\n",
    "    timbre_predictions = np.median(TensorflowPredict2D(graphFilename=MODELS_PATH+'/timbre-discogs-effnet-1.pb', output=\"model/Softmax\")(discogs_embeddings), axis=0)\n",
    "    bright = timbre_predictions[0]\n",
    "    dark = timbre_predictions[1]   \n",
    "    \n",
    "    # Reverb (Dry/Wet)\n",
    "    reverb_predictions = np.median(TensorflowPredict2D(graphFilename=MODELS_PATH+'/nsynth_reverb-discogs-effnet-1.pb', output=\"model/Softmax\")(discogs_embeddings), axis=0)\n",
    "    dry = reverb_predictions[0]\n",
    "    wet = reverb_predictions[1]\n",
    "    \n",
    "    # Return model results\n",
    "    features = {\n",
    "        'Embeddings': vggish_embeddings,\n",
    "        'Approachability': approachability,\n",
    "        'Engagement': engagement,\n",
    "        'Valence': valence,\n",
    "        'Arousal': arousal,\n",
    "        'Aggressive': aggressive,\n",
    "        'Happy': happy,\n",
    "        'Party': party,\n",
    "        'Relaxed': relaxed,\n",
    "        'Sad': sad,\n",
    "        'Jamendo Labels': jamendo_dict,\n",
    "        'Jamendo Instruments': jamendo_instrument_dict,\n",
    "        'Acoustic': acoustic,\n",
    "        'Electronic': electronic,\n",
    "        'Voice': voice,\n",
    "        'Instrumental': instrumental,\n",
    "        'Male': male,\n",
    "        'Female': female,\n",
    "        'Bright': bright,\n",
    "        'Dark': dark,\n",
    "        'Dry': dry,\n",
    "        'Wet': wet\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e934df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(audio_file):\n",
    "    # Load the audio file\n",
    "    audio44k = MonoLoader(filename=audio_file)()\n",
    "    audio16k = MonoLoader(filename=audio_file, sampleRate=16000)()\n",
    "\n",
    "    # Run algorithms\n",
    "    algorithm_features = run_essentia_models(audio44k, audio16k)\n",
    "\n",
    "    # Merge results\n",
    "    return algorithm_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236a2bf",
   "metadata": {},
   "source": [
    "#### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d1b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class constructed from song path\n",
    "# Song path must follow this format: /some/path/(int)^(video id)^(title).mp3\n",
    "#                               e.g  /some/path/0^LlWGt_84jpg^Special Breed.mp3\n",
    "class SongPath:\n",
    "    def __init__(self, song_path: str):\n",
    "        self.path = song_path\n",
    "        self.filename = os.path.basename(song_path)\n",
    "\n",
    "        song_filename_split = self.filename.split('^')\n",
    "        if len(song_filename_split) != 3:\n",
    "            raise Exception(\"The song's filename doesn't follow the correct format: /some/path/(int)^(video id)^(title).mp3\")\n",
    "        \n",
    "        self.index, self.video_id, self.title_with_extension = song_filename_split\n",
    "\n",
    "        self.index = int(self.index)\n",
    "        self.title = os.path.splitext(self.title_with_extension)[0]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Idx: {self.index},  videoID: {self.video_id}, title: {self.title_with_extension}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1815d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song(song_path):\n",
    "    song = SongPath(song_path)\n",
    "    song_features = extract_audio_features(song.path)\n",
    "    return song.index, song_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_songs():\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    song_paths = np.array([os.path.join(DOWNLOAD_FOLDER, song_filename) for song_filename in os.listdir(DOWNLOAD_FOLDER)])\n",
    "\n",
    "    #songs_data_lower, songs_data_higher = [len(song_paths)//6*0, len(song_paths)//6*1]\n",
    "    songs_data_lower, songs_data_higher = [0, 4]\n",
    "    song_paths = song_paths[songs_data_lower:songs_data_higher]\n",
    "    \n",
    "    with mp.Manager() as manager:\n",
    "        kill_thread = manager.Value('b', False)\n",
    "\n",
    "        main_process = psutil.Process(os.getpid())\n",
    "        memory_thread = threading.Thread(target=monitor_memory_usage, args=(main_process, kill_thread))\n",
    "        memory_thread.start()\n",
    "        \n",
    "        song_results = []\n",
    "        for song_path in song_paths:\n",
    "            processed_song = process_song(song_path)\n",
    "            song_results.append(processed_song)\n",
    "                    \n",
    "        kill_thread.value = True\n",
    "\n",
    "    # Aggregate results in the pandas dataframe\n",
    "    songs_data_full = songs_data.copy(deep=True)\n",
    "    for song_index, song_features in song_results:\n",
    "        for feature, value in song_features.items():\n",
    "            if feature not in songs_data_full.columns and isinstance(value, (tuple, set, list, np.ndarray, dict)):\n",
    "                songs_data_full[feature] = np.nan\n",
    "                songs_data_full[feature] = songs_data_full[feature].astype(object)\n",
    "            songs_data_full.at[song_index, feature] = value\n",
    "\n",
    "    return songs_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "281eba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Process 46664': 608.93359375, 'Child Process 51358': 0.0}\n",
      "Thread ERROR: the tracemalloc module must be tracing memory allocations to take a snapshot\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TensorflowPredictEffnetDiscogs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m songs_data_full \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_songs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m songs_data_full\n",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m, in \u001b[0;36mprocess_songs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m song_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m song_path \u001b[38;5;129;01min\u001b[39;00m song_paths:\n\u001b[0;32m---> 17\u001b[0m     processed_song \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_song\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     song_results\u001b[38;5;241m.\u001b[39mappend(processed_song)\n\u001b[1;32m     20\u001b[0m kill_thread\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m, in \u001b[0;36mprocess_song\u001b[0;34m(song_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_song\u001b[39m(song_path):\n\u001b[1;32m      2\u001b[0m     song \u001b[38;5;241m=\u001b[39m SongPath(song_path)\n\u001b[0;32m----> 3\u001b[0m     song_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_audio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m song\u001b[38;5;241m.\u001b[39mindex, song_features\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mextract_audio_features\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m audio16k \u001b[38;5;241m=\u001b[39m MonoLoader(filename\u001b[38;5;241m=\u001b[39maudio_file, sampleRate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run algorithms\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m algorithm_features \u001b[38;5;241m=\u001b[39m \u001b[43mrun_essentia_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio44k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio16k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Merge results\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithm_features\n",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m, in \u001b[0;36mrun_essentia_models\u001b[0;34m(audio16k, audio44k)\u001b[0m\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m discogs_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mTensorflowPredictEffnetDiscogs\u001b[49m(graphFilename\u001b[38;5;241m=\u001b[39mMODELS_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/discogs-effnet-bs64-1.pb\u001b[39m\u001b[38;5;124m'\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartitionedCall:1\u001b[39m\u001b[38;5;124m\"\u001b[39m)(audio16k)\n\u001b[1;32m      6\u001b[0m vggish_embeddings \u001b[38;5;241m=\u001b[39m TensorflowPredictVGGish(graphFilename\u001b[38;5;241m=\u001b[39mMODELS_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/audioset-vggish-3.pb\u001b[39m\u001b[38;5;124m'\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/vggish/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)(audio16k)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Approachability\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TensorflowPredictEffnetDiscogs' is not defined"
     ]
    }
   ],
   "source": [
    "songs_data_full = process_songs()\n",
    "songs_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa55536",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data_full.dropna(subset=['Danceability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data_full.to_csv('data/songs_data_models_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5807643,
     "sourceId": 9535353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5843102,
     "sourceId": 9582418,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 131168,
     "modelInstanceId": 106837,
     "sourceId": 126903,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 133887,
     "modelInstanceId": 109590,
     "sourceId": 130047,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 133915,
     "modelInstanceId": 109618,
     "sourceId": 130080,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ess-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
