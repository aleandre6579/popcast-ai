{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c19fee",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24d98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "import multiprocessing\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from essentia.standard import (\n",
    "    MonoLoader,\n",
    "    Danceability,\n",
    "    Spectrum,\n",
    "    FrameCutter,\n",
    "    Loudness,\n",
    "    RhythmExtractor2013,\n",
    "    KeyExtractor,\n",
    "    Energy,\n",
    "    TonalExtractor,\n",
    "    Inharmonicity,\n",
    "    MFCC,\n",
    "    OnsetRate,\n",
    "    SpectralCentroidTime,\n",
    "    DynamicComplexity,\n",
    "    SpectralPeaks,\n",
    "    NoveltyCurve,\n",
    "    Spectrum,\n",
    "    FrameGenerator,\n",
    "    Windowing,\n",
    "    MelBands,\n",
    "    BeatsLoudness,\n",
    "    Beatogram,\n",
    "    Meter,\n",
    "    HumDetector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b319e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mtg_jamendo_moodtheme-discogs-effnet-1.json', 'r') as jamendo_file:\n",
    "    jamendo_metadata = json.load(jamendo_file)\n",
    "jamendo_classes = jamendo_metadata['classes']\n",
    "\n",
    "with open('data/mtg_jamendo_instrument-discogs-effnet-1.json', 'r') as jamendo_file:\n",
    "    jamendo_instrument_metadata = json.load(jamendo_file)\n",
    "jamendo_instrument_classes = jamendo_instrument_metadata['classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08a118",
   "metadata": {},
   "source": [
    "#### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02b744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DOWNLOAD_FOLDER = os.getenv('DOWNLOAD_FOLDER')\n",
    "CPU_THREADS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3098f",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beee6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data = pd.read_csv('data/songs_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f582f3b",
   "metadata": {},
   "source": [
    "#### Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4973e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_image(spectrogram_db, sample_rate):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram_db, sr=sample_rate, x_axis='time', y_axis='mel', fmax=11025)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel-Spectrogram\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_spectrogram(audio_path, create_image=False):\n",
    "    mp3, sample_rate = librosa.load(audio_path, sr=22050)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=mp3, sr=sample_rate, n_mels=128, fmax=11025)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    if create_image:\n",
    "        create_spectrogram_image(spectrogram_db, sample_rate)\n",
    "\n",
    "    return spectrogram_db, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd147c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_bands(audio):\n",
    "    spectrum = Spectrum()\n",
    "    frame_generator = FrameGenerator(audio, frameSize=2048, hopSize=1024)\n",
    "    window = Windowing(type='hann')\n",
    "\n",
    "    mel_bands = MelBands(numberBands=40)\n",
    "    mel_band_energies = []\n",
    "\n",
    "    for frame in frame_generator:\n",
    "        spec = spectrum(window(frame))\n",
    "        mel_band_energies.append(mel_bands(spec))\n",
    "\n",
    "    mel_band_energies = np.array(mel_band_energies)\n",
    "    return mel_band_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d555c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_essentia_algorithms(audio44k):\n",
    "    _, mfcc_coeffs = MFCC(inputSize=len(audio44k))(audio44k)\n",
    "    danceability_score = Danceability()(audio44k)\n",
    "    loudness_score = Loudness()(audio44k)\n",
    "    bpm, beat_positions, _, _, _ = RhythmExtractor2013(method=\"multifeature\")(audio44k)\n",
    "    key, scale, _ = KeyExtractor()(audio44k)\n",
    "    energy_score = Energy()(audio44k)\n",
    "\n",
    "    ### Chord Significances\n",
    "    _, _, _, _, chords, _, _, _, _, _, _, _ = TonalExtractor()(audio44k)\n",
    "    unique_chords, counts = np.unique(chords, return_counts=True)\n",
    "    chords_significance = {chord: significance for (chord, significance) in zip(unique_chords, counts)}\n",
    "    \n",
    "    ### Inharmonicity\n",
    "    frames = []\n",
    "    frameCutter = FrameCutter()\n",
    "    while True:\n",
    "        frame = frameCutter(audio44k)\n",
    "        if not len(frame):\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        \n",
    "    spectrum_magnitudes = []\n",
    "    for frame in frames:\n",
    "        spectrum_magnitudes_frame = Spectrum()(frame)\n",
    "        spectrum_magnitudes.append(spectrum_magnitudes_frame)\n",
    "    spectrum_magnitudes = np.array(spectrum_magnitudes).flatten()\n",
    "    \n",
    "    frequencies, magnitudes = SpectralPeaks()(audio44k)\n",
    "    hnr_score = None\n",
    "    if frequencies[0]: \n",
    "        hnr_score = Inharmonicity()(frequencies, magnitudes)\n",
    "    ###\n",
    "    \n",
    "    onset_rate_score = OnsetRate()(audio44k)\n",
    "    brightness_score = SpectralCentroidTime()(audio44k)\n",
    "    dynamic_complexity_score, _ = DynamicComplexity()(audio44k)\n",
    "    \n",
    "    mel_bands = get_mel_bands(audio44k)\n",
    "    novelty_curve = NoveltyCurve()(mel_bands)\n",
    "    novelty_score = np.median(np.abs(np.diff(novelty_curve)))\n",
    "    \n",
    "    beats_loudness, beats_loudness_band_ratio = BeatsLoudness(beats=beat_positions)(audio44k)\n",
    "    beatogram = Beatogram()(beats_loudness, beats_loudness_band_ratio)\n",
    "    time_signature = Meter()(beatogram)\n",
    "    \n",
    "    _, _, saliences, hum_starts, hum_ends = HumDetector()(audio44k)\n",
    "    hum_intervals = [(hum_start, hum_end, salience) for hum_start, hum_end, salience in zip(hum_starts, hum_ends, saliences)]\n",
    "        \n",
    "    features = {\n",
    "        'Danceability': danceability_score[0],\n",
    "        'Loudness': loudness_score,\n",
    "        'BPM': bpm,\n",
    "        'Key': key,\n",
    "        'Key Scale': scale,\n",
    "        'Energy': energy_score,\n",
    "        'Chords Significance': chords_significance,\n",
    "        'Inharmonicity': hnr_score,\n",
    "        'Timbre (MFCC Coefficients Mean)': np.mean(mfcc_coeffs),\n",
    "        'Onset Rate': onset_rate_score[1],\n",
    "        'Brightness': brightness_score,\n",
    "        'Dynamic Complexity': dynamic_complexity_score,\n",
    "        'Novelty': novelty_score,\n",
    "        'Time Signature': time_signature,\n",
    "        'Hum Intervals': hum_intervals\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e934df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(audio_file):\n",
    "    # Load the audio file\n",
    "    #audio16k = MonoLoader(filename=audio_file, sampleRate=16000)()\n",
    "    audio44k = MonoLoader(filename=audio_file)()\n",
    "\n",
    "    algorithm_features = run_essentia_algorithms(audio44k)\n",
    "    spectrogram, sample_rate = convert_mp3_to_spectrogram(audio_file)\n",
    "\n",
    "    # Merge results and return\n",
    "    features = algorithm_features | {'Spectrogram': spectrogram, 'Spectrogram Sample Rate': sample_rate}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236a2bf",
   "metadata": {},
   "source": [
    "#### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1815d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song(song, song_index, np):\n",
    "    song_id = song.get('videoID')\n",
    "    if not song_id:\n",
    "        print(f\"Error: videoID not found. Song: {song}\")\n",
    "        return\n",
    "\n",
    "    # Download song\n",
    "    song_path = download_song(song_id, DOWNLOAD_FOLDER)\n",
    "    if not song_path:\n",
    "        return\n",
    "\n",
    "    # Extract song features\n",
    "    song_features = extract_audio_features(song_path)\n",
    "\n",
    "    for feature, value in song_features.items():\n",
    "        if isinstance(value, (tuple, set, list, np.ndarray, dict)) and feature not in np.shared_songs_data.columns:\n",
    "            np.shared_songs_data[feature] = np.nan\n",
    "            np.shared_songs_data[feature] = np.shared_songs_data[feature].astype(object)\n",
    "        np.shared_songs_data.at[song_index, feature] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfdaae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(args, np):\n",
    "    song_batch, batch_num = args\n",
    "    process_times = []\n",
    "    song_count = 0\n",
    "    \n",
    "    for song_index, song in song_batch.iterrows():\n",
    "        song_count += 1\n",
    "        startTime = time.time()\n",
    "        process_song(song, song_index, np.songs_data)\n",
    "        process_time = time.time() - startTime\n",
    "        process_times.append(process_time)\n",
    "        print(f\"Batch {batch_num}, Song {song_count}/{len(song_batch)}: {process_time:.2f} seconds. Avg extraction time: {np.mean(process_times):.2f}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5807643,
     "sourceId": 9535353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5843102,
     "sourceId": 9582418,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 131168,
     "modelInstanceId": 106837,
     "sourceId": 126903,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 133887,
     "modelInstanceId": 109590,
     "sourceId": 130047,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 133915,
     "modelInstanceId": 109618,
     "sourceId": 130080,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
